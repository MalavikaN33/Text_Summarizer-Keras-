{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seq2seq import Seq2SeqSummarizer\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to always load the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_EXISTING_WEIGHTS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some hyper parameter values for the encoder and decoder networks as well as the nynber of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT_SEQ_LENGTH = 500\n",
    "MAX_TARGET_SEQ_LENGTH = 50\n",
    "MAX_INPUT_VOCAB_SIZE = 5000\n",
    "MAX_TARGET_VOCAB_SIZE = 2000\n",
    "EPOCHS = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a text preprocessing method for the neural network inputs\n",
    "\n",
    "The output of this method is the configuration of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_text(X, Y, input_seq_max_length=None, target_seq_max_length=None):\n",
    "    if input_seq_max_length is None:\n",
    "        input_seq_max_length = MAX_INPUT_SEQ_LENGTH\n",
    "    if target_seq_max_length is None:\n",
    "        target_seq_max_length = MAX_TARGET_SEQ_LENGTH\n",
    "    input_counter = Counter()\n",
    "    target_counter = Counter()\n",
    "    max_input_seq_length = 0\n",
    "    max_target_seq_length = 0\n",
    "\n",
    "    for line in X:\n",
    "        text = [word.lower() for word in line.split(' ')]\n",
    "        seq_length = len(text)\n",
    "        if seq_length > input_seq_max_length:\n",
    "            text = text[0:input_seq_max_length]\n",
    "            seq_length = len(text)\n",
    "        for word in text:\n",
    "            input_counter[word] += 1\n",
    "        max_input_seq_length = max(max_input_seq_length, seq_length)\n",
    "\n",
    "    for line in Y:\n",
    "        line2 = 'START ' + line.lower() + ' END'\n",
    "        text = [word for word in line2.split(' ')]\n",
    "        seq_length = len(text)\n",
    "        if seq_length > target_seq_max_length:\n",
    "            text = text[0:target_seq_max_length]\n",
    "            seq_length = len(text)\n",
    "        for word in text:\n",
    "            target_counter[word] += 1\n",
    "            max_target_seq_length = max(max_target_seq_length, seq_length)\n",
    "\n",
    "    input_word2idx = dict()\n",
    "    for idx, word in enumerate(input_counter.most_common(MAX_INPUT_VOCAB_SIZE)):\n",
    "        input_word2idx[word[0]] = idx + 2\n",
    "    input_word2idx['PAD'] = 0\n",
    "    input_word2idx['UNK'] = 1\n",
    "    input_idx2word = dict([(idx, word) for word, idx in input_word2idx.items()])\n",
    "\n",
    "    target_word2idx = dict()\n",
    "    for idx, word in enumerate(target_counter.most_common(MAX_TARGET_VOCAB_SIZE)):\n",
    "        target_word2idx[word[0]] = idx + 1\n",
    "    target_word2idx['UNK'] = 0\n",
    "\n",
    "    target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
    "    \n",
    "    num_input_tokens = len(input_word2idx)\n",
    "    num_target_tokens = len(target_word2idx)\n",
    "\n",
    "    config = dict()\n",
    "    config['input_word2idx'] = input_word2idx\n",
    "    config['input_idx2word'] = input_idx2word\n",
    "    config['target_word2idx'] = target_word2idx\n",
    "    config['target_idx2word'] = target_idx2word\n",
    "    config['num_input_tokens'] = num_input_tokens\n",
    "    config['num_target_tokens'] = num_target_tokens\n",
    "    config['max_input_seq_length'] = max_input_seq_length\n",
    "    config['max_target_seq_length'] = max_target_seq_length\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the neural network and train the network on the input data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "data_dir_path = \"./data/\"\n",
    "\n",
    "model_dir_path = './models/'\n",
    "\n",
    "print('loading csv file ...')\n",
    "df = pd.read_csv(data_dir_path + \"train.csv\")\n",
    "\n",
    "print('extract configuration from input texts ...')\n",
    "Y = df['Summary']\n",
    "X = df['Full Text']\n",
    "\n",
    "config = fit_text(X, Y)\n",
    "\n",
    "summarizer = Seq2SeqSummarizer(config)\n",
    "\n",
    "if LOAD_EXISTING_WEIGHTS:\n",
    "    summarizer.load_weights(weight_file_path=Seq2SeqSummarizer.get_weight_file_path(model_dir_path=model_dir_path))\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('demo size: ', len(Xtrain))\n",
    "print('testing size: ', len(Xtest))\n",
    "\n",
    "print('start fitting ...')\n",
    "summarizer.fit(Xtrain, Ytrain, Xtest, Ytest, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reusing a saved model (for prediction purposes only)\n",
    "\n",
    "Using the test data to validate the prediction of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading csv file ...\n",
      "Model summary\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, 500, 100)     500200      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 2001)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 100), (None, 80400       encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 100),  840800      decoder_inputs[0][0]             \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 2001)   202101      decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,623,501\n",
      "Trainable params: 1,623,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "start predicting ...\n",
      "Predictions done\n"
     ]
    }
   ],
   "source": [
    "print('loading csv file ...')\n",
    "data_dir_path = \"./data/\"\n",
    "\n",
    "model_dir_path = './models/'\n",
    "\n",
    "df = pd.read_csv(data_dir_path + \"train.csv\")\n",
    "Y = df['Summary']\n",
    "X = df['Full Text']\n",
    "\n",
    "config = np.load(Seq2SeqSummarizer.get_config_file_path(model_dir_path=model_dir_path), allow_pickle=True).item()\n",
    "\n",
    "summarizer = Seq2SeqSummarizer(config)\n",
    "summarizer.load_weights(weight_file_path=Seq2SeqSummarizer.get_weight_file_path(model_dir_path=model_dir_path))\n",
    "\n",
    "print('start predicting ...')\n",
    "\n",
    "op_data = pd.DataFrame(columns=['Index', 'Article', 'Original Summary', 'Generated Summary'])\n",
    "\n",
    "for i in np.random.permutation(np.arange(len(X)))[0:20]:\n",
    "    x = X[i]\n",
    "    actual_summary = Y[i]\n",
    "    gen_summary = summarizer.summarize(x)\n",
    "    op_data = op_data.append({\n",
    "        'Index': i, \n",
    "        'Article': x, \n",
    "        'Original Summary': actual_summary, \n",
    "        'Generated Summary': gen_summary\n",
    "    }, ignore_index = True)\n",
    "#     print('Article: ', x)\n",
    "#     print('Generated Summary: ', gen_summary)\n",
    "#     print('Original Summary: ', actual_summary)\n",
    "\n",
    "print(\"Predictions done\")\n",
    "op_data.to_csv(\"output_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Article</th>\n",
       "      <th>Original Summary</th>\n",
       "      <th>Generated Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>Hyderabad-based drugmaker Dr Reddy's Laborator...</td>\n",
       "      <td>Indian drugmaker Dr Reddy's Laboratories said ...</td>\n",
       "      <td>former australian batsman matthew hayden has m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>Patidar leader Hardik Patel on Wednesday rubbi...</td>\n",
       "      <td>Patidar leader Hardik Patel on Wednesday asked...</td>\n",
       "      <td>finance minister arun jaitley has alleged that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Peeling onions have seldom been a loving task....</td>\n",
       "      <td>IIT Kharagpur and South Korea-based researcher...</td>\n",
       "      <td>iit kharagpur and south korea-based researcher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>Developing voice assistant and speech recognit...</td>\n",
       "      <td>US-based Cisco's Executive Chairman John Chamb...</td>\n",
       "      <td>us-based cisco's executive chairman has picked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>At a time when Flipkart's valuation has been m...</td>\n",
       "      <td>Amazon on Wednesday said that it has more than...</td>\n",
       "      <td>reacting to bihar has said that he should not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index                                            Article  \\\n",
       "0    45  Hyderabad-based drugmaker Dr Reddy's Laborator...   \n",
       "1    70  Patidar leader Hardik Patel on Wednesday rubbi...   \n",
       "2     6  Peeling onions have seldom been a loving task....   \n",
       "3    88  Developing voice assistant and speech recognit...   \n",
       "4    99  At a time when Flipkart's valuation has been m...   \n",
       "\n",
       "                                    Original Summary  \\\n",
       "0  Indian drugmaker Dr Reddy's Laboratories said ...   \n",
       "1  Patidar leader Hardik Patel on Wednesday asked...   \n",
       "2  IIT Kharagpur and South Korea-based researcher...   \n",
       "3  US-based Cisco's Executive Chairman John Chamb...   \n",
       "4  Amazon on Wednesday said that it has more than...   \n",
       "\n",
       "                                   Generated Summary  \n",
       "0  former australian batsman matthew hayden has m...  \n",
       "1  finance minister arun jaitley has alleged that...  \n",
       "2  iit kharagpur and south korea-based researcher...  \n",
       "3  us-based cisco's executive chairman has picked...  \n",
       "4  reacting to bihar has said that he should not ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"The main purpose of refactoring is to fight technical debt. It transforms a mess into clean code and simple design. The user should initiate the program by running the java code through the command prompt or terminal, depending on the operating system. By running the program, a FilerReader class and the BufferedReader class from java.io package is used to take input frvements depend a lot on the skills of the maintainer. Coupling and cohesion on the other hand are quality attributes which are generally recognizedas being among the most likely quantifiable indicators for software maintainability. Therefore, this paper analyze show refactorings manipulate coupling/cohesion character-istics, and how to identify refactoring opportunities that improve these characteristics. As such we provide practicalguidelines for the optimal usage of refactoring in a software maintenance process. Refactorings behavior preserving source code transformations — allow the automated redistribution of pieces of source code over the class hierarchy. The underlying objective is to improve the quality of the software system,with regard to future maintenance and development activities. Unfortunately, while it is clear that we can use refactorings to restructure software systems, it is unclear how to use them in order to improve specific quality attributes thatare indicators for a good design. We start from the assumption that coupling and cohesion characteristics may serve as indicators for the optimal distribution of responsiblities over the class hierarchies. Thus, rather than saying that refactoring will improve the design, we aim for a less ambitious goal of improving the coupling and cohesion. Cohesion then corresponds to the degree to which elements of a class belong together, and coupling is the strength of association established by a connection from one class to another.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'former australian batsman matthew has been appointed as the upcoming state assembly and bharat will to their government on the region on all reports that china is maintaining a sizeable number of troops in and others of its from six called called called if called if this will to be'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.summarize(\"The main purpose of refactoring is to fight technical debt. It transforms a mess into clean code and simple design. The user should initiate the program by running the java code through the command prompt or terminal, depending on the operating system. By running the program, a FilerReader class and the BufferedReader class from java.io package is used to take input frvements depend a lot on the skills of the maintainer. Coupling and cohesion on the other hand are quality attributes which are generally recognizedas being among the most likely quantifiable indicators for software maintainability. Therefore, this paper analyze show refactorings manipulate coupling/cohesion character-istics, and how to identify refactoring opportunities that improve these characteristics. As such we provide practicalguidelines for the optimal usage of refactoring in a software maintenance process. Refactorings behavior preserving source code transformations — allow the automated redistribution of pieces of source code over the class hierarchy. The underlying objective is to improve the quality of the software system,with regard to future maintenance and development activities. Unfortunately, while it is clear that we can use refactorings to restructure software systems, it is unclear how to use them in order to improve specific quality attributes thatare indicators for a good design. We start from the assumption that coupling and cohesion characteristics may serve as indicators for the optimal distribution of responsiblities over the class hierarchies. Thus, rather than saying that refactoring will improve the design, we aim for a less ambitious goal of improving the coupling and cohesion. Cohesion then corresponds to the degree to which elements of a class belong together, and coupling is the strength of association established by a connection from one class to another.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "parser = PlaintextParser.from_string(x, Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary by EdmundsonSummarizer\n",
      "The main purpose of refactoring is to fight technical debt.\n",
      "The user should initiate the program by running the java code through the command prompt or terminal, depending on the operating system.\n",
      "As such we provide practicalguidelines for the optimal usage of refactoring in a software maintenance process.\n"
     ]
    }
   ],
   "source": [
    "print (\"summary by EdmundsonSummarizer\")     \n",
    "edsummarizer = EdmundsonSummarizer() \n",
    "words = (\"refactoring\", \"java\" )\n",
    "edsummarizer.bonus_words = words\n",
    "     \n",
    "words = (\"another\", \"and\", \"some\", \"next\",)\n",
    "edsummarizer.stigma_words = words\n",
    "    \n",
    "     \n",
    "words = (\"another\", \"and\", \"some\", \"next\",)\n",
    "edsummarizer.null_words = words\n",
    "for sentence in edsummarizer(parser.document, 3):\n",
    "    print(sentence)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
