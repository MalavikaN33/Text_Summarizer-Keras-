Index,Title,Summary,Full Text,Url
101,Was a day away from shutting everything: Zoomcar Co-founder,"While talking about the starting days of car rental startup Zoomcar, Co-founder Greg Moran has said, ""I was a day away from shutting down everything."" He also said, ""I had put in all of my savings into Zoomcar, and it was suddenly a make-or-break situation."" Greg added that the startup faced an initial lack of trust from local vendors.","Zoomcar has been in operations for five years. The Bengaluru-based car rental platform has a fleet of nearly 3000 cars spread over 26 cities and has raised over $45 million in funding. Recalls Greg Moran, Co-founder and CEO Zoomcar. Friends Greg and David Back, who studied together at the University of Pennsylvania, had come to India to start up a business and had zeroed in on the idea of Zoomcar. Today, the Bengaluru-based car rental platform has a presence in 26 cities across the country and has tie-ups with the likes of Mahindra & Mahindra, Ford, and Tata Motors. It has raised over $45 million in seven rounds of funding, and counts biggies like Sequoia Capital as its investors. The going, however, has been far from easy. My interests academically were always geared towards India and China. After my education in the US, I took up a career in banking. I knew everything about India before coming to Bangalore - had friends from the country, a working idea of what the country was like, and felt that it was a largely unexplored market, says Greg. With a leave of absence from his Wall Street job as an investment banker, Greg decided to explore India more than just on paper. Landing here with David, the duo soon realised that while there was a strong business potential for car rentals, there were several infrastructural challenges. The two had, in fact, also dabbled with the idea of starting a company in the renewable energy space, but later decided on the transportation sector. Greg believed the transport sector in India needed disruption, and in 2011, he and David conceptualised Zoomcar as an hourly car rental platform. Car ownership, according to Greg and David, would hit a wall in India due to infrastructure and economic reasons - it is an expensive proposition to own a car in the country, and available infrastructure posed challenges to owning one. While owning a car came with a certain snob value, there were also many who said having such an asset was a waste of money. We actually beat Uber by a couple of months. Ola was already present in the market, and they were following a taxi aggregation model, says Greg. Apart from this, there were Meru and Mega Cabs. The car rental space had Carzonrent, Avis and Car Club, but the market was still nascent. As the duo researched the market, prevailing transport regulations posed to be the biggest challenge. To start a car rental business in India, Zoomcar needed a license, and could not get one on their own. Because according to Contract Carriage Permit, you need to have yellow board licence plate vehicles, to do so you need to own a fleet or tie up with an owner of a fleet. Add to that, they had already received a seed funding and tied up with several car makers for their fleet. I had put in all of my savings into Zoomcar, and it was suddenly a make-or-break situation, says Greg. The only way out was to work with an existing player that already had a license. At that point in time, there were five of those , says Greg. Four rejected Zoomcar outright, and it was down to the wire as they met with Ramesh Tours and Travels. If this did not work out too, for Greg it meant he would not return to India after his Christmas vacation. Greg says, People who are not entrepreneurs do not realise that in India, it is so much easier to start a business in certain sectors. In transportation, on a relative basis, it is still a lot harder to start a business. It is much easier to start something like a SaaS business or a pure tech company. There are no niche permits and licenses required, getting which tends to be very slow and opaque. Getting to the start line was something that was incredibly difficult. Also, Greg says, there was an initial lack of trust. Local vendors took time to accept that the company was serious about starting a business in India. With the tie-up with Ramesh Tours and Travels, Zoomcar launched operations in 2013, and began with a few cars from Mahindra & Mahindra. However, Greg adds that until about 2015, the platform was run manually. It did put us in a hole, because at the scale we were at, we did not have the system to cope when it came to engineering, says Greg. Zoomcar soon raised funding of $300,000, and then $400,000 in 2013. Later the same year, it raised a small seed investment and in 2014, it roped in Sequoia Capital. After that, it was all a matter of execution, says Greg. The capital helped hire a stronger tech team and Zoomcar got in Ford as one of its investors as well. Over the past five years, while Zoomcar has continued to rent out cars on an hourly basis, it nevertheless has also brought in several changes. Today, one can have a car delivered to their location, the company has added airport locations, and can cater to higher customer requirements. Early this year, it also launched ZAP, which allows a customer to borrow a car directly from her neighbour. To do this, Zoomcar brought into its inventory cars that it had not bought. Zoomcar can rent out an owner's car when not in use. Once a vehicle is acquired, it joins the Zoomcar fleet, and the company pays the owner when it is used. A 25 percent commission on revenue is charged from associates. The platform currently has a fleet of 2,600-3000 vehicles, which is a mix of company-owned and third claims. Its customer base, is more than two million. The platform is also evaluating a shift to a marketplace model, and may phase out the current model. ZAP is a step in that direction. Zoomcar was named among the top 10 most innovative companies from India early this year. Recently, it launched Cadabra, a full-stack solution to transform its fleet into Internet of Things (IoT) -enabled vehicles. Any anomaly in driver behaviour emits a harsh sound, leading to alertness and reducing accidents. We have already been able to reduce accidents by 35 percent over the last three months. That's something we are truly happy about, and we are actually quite confident that we will be able to reduce accidents by another 50 percent. Zoomcar also recently tied up with Israeli company Mobileye NV, which provides advanced driver assistance systems that use image processing technology to warn drivers and prevent accidents caused by lack of attention. Car rentals make it easy to drive in and around the city, especially if you need a vehicle for short timelines, or if you are travelling to a different city. It brings in a lot of freedom and convenience, says a 42-year-old marketing executive. Recently, Zoomcar launched HOP, for intercity rentals. While Zoomcar has an early mover advantage, today there are several car rental platforms like Drivezy, which recently raised $10 million in external funding. However, according to Ken Research, few car rental companies have been able to penetrate into Tier II and Tier III cities. Also, over 70 percent of the car rental market at present is dominated by the unorganised segment. According to analysts, with Ola and Uber now entering the car rentals market, players like Zoomcar and Drivezy will face stiff competition. One industry expert added that with cab aggregator platforms raising funds to the tune of billions of dollars, they have the capital to explore options, penetrate deeper into the market, and fight competition. Jaspal Singh, Partner at Valoriser Consultants, says that while the car rental market offers a big opportunity in India, it yet is to see the traction seen in other countries. It isn't about whether the car rental will work, it is about will a company be able to break the market. There is no doubt there exists a market for car rentals in India. But it still has a long way to go before it becomes mature like a European or the US market. Also, investments in the space are relatively lower in India because several investors are wary if it will touch a larger market than the metros, adds Jaspal. Greg says Zoomcar runs on a different model, and the focus is on customers who want to have the freedom of a car at any time, for a longer duration. With 75 percent occupancy and 1.5 million app downloads, Zoomcar is India's largest app-based self-drive car rental company. According to the company's revenue details shared with the Registrar of Companies (RoC) and MCA, its revenue for FY 2016-17 stood at Rs 121.2 crore and loss at Rs 104 crore. In FY 2015-2016, its total revenue was at Rs 89.82 crore. We are already profitable in most cities, and this gives us net margins well over 50 percent. We are going to continue to invest because we know that this will reap huge benefits when it comes to customers, says Greg.",https://yourstory.com/2017/11/zoomcar-braved-a-near-shutdown-before-india-car-rental-poster-boy/?utm_campaign=awesummly&utm_source=awesummly
102,SoftBank may invest up to $250 million in Swiggy,"Japanese conglomerate SoftBank may invest up to $250 million in Bengaluru-based food delivery startup Swiggy, according to reports. China's Tencent, Alibaba, and Indian e-commerce major Flipkart are also in talks to invest in the food delivery startup, reports added. Earlier in May, Swiggy had raised â‚¹517 crore funding led by Naspers.","After solidifying its position in the Indian ecommerce and cab aggregator space, Japanese conglomerate SoftBank is reportedly gearing up for a $200 Mn-$250 Mn investment in foodtech startup, Swiggy. With this, SoftBank has joined Flipkart and China-headquartered Tencent, both of which are holding discussions with the Naspers-backed online food delivery platform for a potential investment. As per reports, SoftBank is looking to pick up a minority stake in Swiggy, in exchange for $200 Mn-$250 Mn. If successful, the investment would likely take place at a pre-money valuation of $600 Mn-$650 Mn. A spokesperson for Swiggy stated, Swiggy garners continuous interest from investors due to our market leadership position, strong growth and financial performance. We remain focused on delivering exceptional value to consumers, and will comment on fundraises at the opportune time. SoftBank, however, declined to comment on the development, calling it a speculation. Chinese Internet giant Tencent is also reportedly looking to co-invest in the round, in addition to pouring an additional $50 Mn into Swiggy. This, according to sources, would take Tencent's proposed investment in the online food delivery startup to around $100 Mn. Joining the bandwagon is Jack Ma-led Alibaba, which has expressed interest in backing Swiggy through its payments arm Ant Financial. Interestingly, the ecommerce behemoth is currently engaged in talks with Swiggy's chief competitor, Zomato, for a proposed $200 Mn investment. If fruitful, the round would value Zomato at about $1.1 Bn. Reports of Flipkart initiating acquisition talks with Swiggy first surfaced in October, when it was said that the homegrown ecommerce player was gearing up to diversify its business through acquisitions and investment. Most recently, in the third week of November, The Ken reported that Flipkart was preparing for a possible infusion of $50 Mn in Swiggy. Headquartered in Bengaluru, the foodtech startup has raised a total of $155.5 Mn funding to date. In May this year, the company raised $80 Mn in a round led by Naspers at an estimated valuation of $400 Mn. The round also saw participation from existing investors Accel India, SAIF Partners, Bessemer Venture Partners, Harmony Partners and Norwest Venture Partners. Earlier in September 2016, Swiggy picked up $15 Mn Series D funding led by US-based venture capital firm Bessemer Venture Partners and other existing investors. Swiggy reported revenues of over $3.6 Mn and losses of about $21.3 Mn for FY2015-16, as per regulatory filings with RoC. It has since witnessed a nearly 6x jump in revenues during FY17. In last several months, the company has been introducing new products and services as part of its efforts to make a comeback, after several setbacks in the form of controversies and losses. In September this year, it was reported that Swiggy was in the process of building a new cloud kitchen vertical. While Zomato's first Cloud Kitchen came up in Dwarka in March 2017, Swiggy won the race when it launched its cloud kitchen, The Bowl Company in January. The cloud kitchen caters to select areas in Bengaluru and provides Pan-Asian, Continental, Indian cuisines. Recently in November, it announced the launch of a strategic initiative aimed at reaching more customers and making its delivery more seamless. Dubbed as Swiggy Access, the new service allows restaurant partners to set up kitchen spaces in areas where they do not have a physical presence. In an interaction with Inc42, a spokesperson from Swiggy stated that the company clocked 4 Mn orders in July 2017 with a steady increase since. It has partnered with more than 20,000 restaurants so far. Incidentally, earlier this month, reports surfaced that Zomato and Swiggy were holding discussions for a potential stock-based merger, on the basis of a 4:1 share swap. However, as per sources, the talks ultimately failed due to differences in valuations and business alignments. According to another study by Netscribes Research, the foodtech sector is expected to expand by 34%-36% between 2015 and 2020.",https://inc42.com/buzz/softbank-swiggy/?utm_campaign=awesummly&utm_source=awesummly
103,SoftBank offers to buy Flipkart shares at $10 bn valuation,"Japan's SoftBank has reportedly offered to buy an undisclosed number of shares in Indian e-commerce giant Flipkart at up to $10 billion valuation. Flipkart's largest investor Tiger Global Management is also expected to sell shares worth $700 million, according to reports. Accel, IDG Ventures, Kalaari Capital and other investors will also participate in the sale, reports added.
","Japanese telecom and internet conglomerate SoftBank Group Corp. has offered to buy shares from investors and former and existing employees of Flipkart Ltd, valuing the e-commerce marketplace at $9-10 billion, three people familiar with the matter said. SoftBank has offered to buy the Flipkart shares in a range of $85-89 per share, the people said on condition of anonymity. The price range values Flipkart slightly lower than the pre-money valuation it clinched in two funding rounds of $1.4 billion each, one from SoftBank in August and the other from eBay Inc., Microsoft Corp. and Tencent Holdings Ltd in April. In August, along with the primary fund infusion into Flipkart, SoftBank had also agreed to buy shares worth $1.2-$1.4 billion from Flipkart shareholders. The share sale and the fund infusion are likely to be completed in December, said the people cited above. The Flipkart-SoftBank deal has transformed Flipkart's ability to compete with Amazon India, giving it a backer that can pump in whatever cash is needed to keep the American retailing giant at bay. The deal is also a boon for India's start-up investors. Flipkart's largest investor Tiger Global Management, whose former employee Kalyan Krishnamurthy is the current Flipkart CEO, is expected to sell shares worth $700 million, the people said. Accel, IDG Ventures, Kalaari Capital and some other investors are also likely to participate in the sale, they said. SoftBank has put certain caps on the quantity each employee can sell, they said. Investment bank Goldman Sachs is managing the share sale. Tiger Global and Flipkart didn't respond to emails seeking comment. The share sale will help Accel record bumper returns on its second fund of $55 million that was launched in 2008. Kalaari will also secure a much-needed large exit after the proposed sale of Snapdeal, its largest portfolio firm, to Flipkart collapsed in August. IDG, which had sold off a small part of its stake in Flipkart last year, will again score attractive returns from the sale to SoftBank. While the share sale is at a lower valuation than Flipkart's peak valuation, it still represents a big win for Tiger Global and Accel, the online retail firm's first investor. For Fixel, the share sale will cut his exposure to Flipkart, in which he had poured roughly $1 billion across several rounds starting in late 2009. Tiger will still be left with a stake of roughly 20% in the firm, said the people cited earlier. Fixel is also arranging a sale of some of his stake in another Indian unicorn Ola, a fourth person said, requesting anonymity. The Business Standard newspaper had reported news of the share sale at ride-hailing company earlier. The Ola deal is the second big financial collaboration between Tiger Global and SoftBank, which were once considered arch rivals. Until the end of last year, the two were the biggest and most influential start-up investors in India. Both had invested roughly $2 billion in internet firms here. But in the course of just four deals and nine months, SoftBank has tripled its start-up investments to more than $6 billion while Tiger Global has avoided investing more in India.",http://www.livemint.com/Companies/QBVZHpX5f43yBKML4HdlFN/SoftBank-offers-to-buy-Flipkart-shares-at-up-to-10-billion.html?utm_campaign=awesummly&utm_source=awesummly
104,Uber net loss widens to $1.4 bn in third quarter: Report,"Uber's net loss has widened to $1.46 billion in the third quarter from $1.06 billion in the previous quarter, according to reports. However, Uber's net revenue surged 21% to $2.01 billion in the third quarter from $1.66 billion in the second one. This comes amid reports suggesting that Tencent and Sequoia Capital alongside SoftBank plan to invest in Uber. ","Uber Technologies Inc.'s net loss widened to $1.46 billion in the third quarter, according to people with knowledge of the matter, as the ride-hailing leader struggled to fend off competition, legal challenges and regulatory scrutiny. The San Francisco-based company reported financials to shareholders as part of a formal bid Tuesday night from a SoftBank Group Corp.-led consortium looking to buy a large block of stock. SoftBank said in an emailed statement that at least two of Uber's early backers intend to sell. The sale of those shares would value the business at $48 billion, a 30 percent discount to the last private valuation. SoftBank and Dragoneer have received indications from Benchmark, Menlo Ventures, and other early investors of their intent to sell shares in the tender offer, a spokesman for SoftBank wrote. Any sales by these shareholders will be pursuant to the same terms and conditions as will be offered to all other eligible holders that participate in the tender offer. Net revenue grew 21 percent to $2.01 billion in the third quarter from $1.66 billion. But losses, which had been narrowing in previous quarters, reversed course. The net loss increased 38 percent from the second quarter, when it was $1.06 billion. Uber has been searching for a chief financial officer to fill a much-needed role ahead of an initial public offering expected in 2019. Ride-hailing companies hold out the promise of creating a whole new industry, but it's tough to make judgments based on their fundamentals, said Masahiko Ishino, an analyst at Tokai Tokyo Securities. Uber has had a rough year, with the ousting of its former chief executive officer, an exodus in the management ranks and last week's disclosure of a concealed hack that exposed personal data of 57 million people. American rival Lyft Inc., meanwhile, is gaining market share. Uber was without a CEO for most of the third quarter - Travis Kalanick resigned under pressure from investors in June, and Dara Khosrowshahi joined in September. The investor group, which hopes to snap up Uber shares on the cheap, offered to pay $32.97 a share in their opening salvo, said people with knowledge of the matter. They may increase the bid or walk away if seller demand is insufficient. SoftBank has committed to invest at least another $1 billion in Uber at a higher valuation of $69 billion if the deal goes through. The blended valuation in the full deal would be $54 billion, one person said. The consortium of buyers have about four weeks to lock in enough investors at the current share price or to offer a higher price. The entire tender process is supposed to conclude by late February.",https://www.bloomberg.com/news/articles/2017-11-29/uber-s-third-quarter-loss-is-said-to-widen-to-1-46-billion?utm_campaign=awesummly&utm_source=awesummly
105,215 eggs from Earth's first flying reptiles found in China,"Brazil and China-based researchers have uncovered 215 fossilised eggs from a 120-million-year-old sandstone block found in China in 2015. The eggs, 16 of which still had remains of embryos, belong to pterosaurs, considered as Earth's first flying vertebrates. The study revealed pterosaurs laid soft-shell eggs, difficult to fossilise, like modern-day lizards, rather than hard-shell eggs like birds.","The largest collection of fossilized pterosaur eggs ever found has shown that pterosaurs, the airborne cousins of dinosaurs, could not fly right away and needed care from their parents, researchers said Thursday. Pterosaurs were reptiles, and the first creatures-after insects-to evolve powered flight, meaning they flapped their wings to stay aloft instead of simply jumping and gliding. First known to exist as many as 225 million years ago, they went extinct along with the dinosaurs about 65 million years ago. Until now, scientists had found some pterosaur eggs with remains inside, including three in Argentina and five in China. But the latest report in the peer-reviewed US journal Science is based on the biggest collection to date-215 fossilized eggs that were found in a 10-foot (three-meter) long sandstone block in northwestern China's Hami City, Xinjiang Uygur Autonomous Region. Since these are extremely fragile fossils, we were very surprised to find so many in the same place, Brazilian paleontologist Alexander Kellner told AFP. Because of this discovery, we can talk about the behavior of these animals for the first time. Sixteen of the eggs contained fossilized remains of a pterosaur species known as Hamipterus tianshanensis. As adults, these creatures would have stood about four feet tall, with a wingspan of 11 feet. None of the eggs held a full set of pterosaur bones, likely because pieces were lost over the years due to storms and floods. But scientists did find partial wing and skull bones, along with one complete lower jaw, which fill in aspects of pterosaurs' life cycle that have been poorly understood until now. Using three-dimensional computed tomography scans, they discovered intact and well-developed thigh bones suggesting the creatures benefited from functional hind legs shortly after hatching, said the report. But their chest muscles were weak. This shows that when pterosaurs hatched, they could walk but not fly, said Kellner. This is one of the biggest discoveries we have made. Adult pterosaur bones were also scattered across the site, a sign that they returned to the same nesting spots over time, much the same as modern day sea turtles. The massive numbers of eggs and bones point to major storms thrashing the site, submerging the eggs in a lake where they floated briefly before sinking and becoming buried alongside adult skeletons. Researchers also noted that the cracked exterior of the eggs resembled the fragile softness of lizard eggs. All are deformed to a certain extent, which indicate their pliable nature, said the study. One of the young pterosaurs was estimated to be at least two years old and still growing at the time of its death, supporting the growing body of evidence that pterosaurs had long incubation periods. An accompanying article in the journal Science, written by D Charles Deeming of the University of Lincoln, called the study remarkable for the number of eggs in association with adults and juvenile pterosaurs that it reports on. Hopefully additional finds of equally spectacular fossils will help us answer such questions, he wrote. Explore further: First 3D pterosaur eggs found with their parents. More information: X Wang el al., Egg accumulation with 3D embryos provides insight into the life history of a pterosaur, Science (2017).",https://phys.org/news/2017-11-hundreds-pterosaur-eggs-reveal-early.html?utm_campaign=awesummly&utm_source=awesummly
106,Bumper-to-bumper car crowding at signal slows traffic: Study,"A US-based study has found that crowding cars with bumper-to-bumper spacing at signals slows down the movement of traffic when the light goes green. Researchers suggested that contrary to popular opinion, if cars stopped farther apart, it would help them accelerate quickly. The team found time required for all cars to pass remained fixed for spacing up to 25 feet.","When pulling up to a traffic light, most drivers get pretty close to the car in front of them, leaving just several feet of space between their bumper and the next. The practice of packing tightly at traffic lights is widely accepted. Traditional thinking says the closer a car is to a traffic light, the more likely that car will be to pass through the intersection before the light turns red again. Thanks to new research by Virginia Tech College of Engineering professors and students, drivers now have a good reason to dismiss this faulty line of roadway intuition. The study, published this month in the New Journal of Physics, used video cameras attached to drone helicopters to capture footage of cars accelerating through a traffic light on the Virginia Tech Transportation Institute's Smart Road. By systematically controlling the packing density of the cars, the researchers discovered that any decrease in distance to the light was completely offset by the time it took for cars to regain a comfortable spacing before drivers could accelerate. Drivers who pack tightly at intersections do not increase their chances of making it through the light, and tailgating at traffic lights can also lead to more rear-end collisions. We varied the bumper-to-bumper spacing between cars by a factor of 20 and saw virtually no change in how much time it took for the cars to pass through the intersection when the light turned green, said Jonathan Boreyko, assistant professor in the Department of Biomedical Engineering and Mechanics. The results mean there's no point in getting closer to the car in front of you when traffic comes to a stop, he said. The inspiration for the research first came to Boreyko when he was sitting in traffic one day. Noticing that cars had to wait for the car in front of them to regain a safe spacing before they could start moving again, he hypothesized that, contrary to popular opinion, it might actually be better for cars to stop farther apart from each other when idling at a traffic light. He teamed up with Farzad Ahmadi, a fourth-year Ph. D student in Virginia Tech's engineering mechanics program and the study's lead author, to investigate. Using 10 volunteer drivers in identical vehicles, the researchers staged a series of experiments at the traffic light on the Virginia Tech Transportation Institute's Smart Road. Drivers systematically lined up at the light in a set of distances ranging from 1.25 to 50 feet, and a drone helicopter hovering overhead captured controlled bird's-eye-view footage of the traffic as drivers accelerated through the light. Analysis showed that the time required for all cars to pass through remained relatively fixed, give or take about one second, for spacing distances up to 25 feet. The two researchers used the thermodynamic concept of latent heat, the energy that a system loses during melting or evaporation, to describe what happens to cars stopped at a traffic light. Vehicles are jammed into a solid phase at a light and must waste energy melting back into a liquid phase before they can actually move through the intersection. Boreyko and Ahmadi wondered if latent heat would have such a dramatic effect on other systems, such as slow-moving pedestrian traffic. The researchers set up a second round of experiments in The Cube at Virginia Tech's Moss Arts Center, a highly adaptable theater and laboratory equipped with synchronized cameras. Undergraduate students Hunter Morgan, Josam Waterman, Pat Greer, and Will Doty - all in the engineering science and mechanics program and co-authors of the study - added a few conditions to their senior design experiments on human crowds to test Boreyko and Ahmadi's hypothesis. Latent heat had almost no effect for a line of pedestrians, said Boreyko. The closer people got to each other, the faster they could empty the line. We realized that people move very slowly, but can accelerate very quickly, which minimizes the lag effect we saw with the cars at the traffic light. The study's findings suggest that both pedestrians and drivers alike could see considerable benefits when taking a mindful approach to packing density in lines. Pedestrians waiting in a line should get as close to each other as possible if it's important for the line to empty quickly, said Boreyko. When you encounter a traffic jam or stop at a light, keep a safe and comfortable distance. You can just maintain whatever spacing you had when you were driving at full speed. You won't lose any time, but you'll reduce the odds of an accidental rear-end collision. When my father was teaching me how to drive, he told me that to prevent an accident, you should stop so you can easily see the rear bumper of the car in front of you at a traffic light, said Ahmadi. I've never done that until I analyzed the data of this experiment. Explore further: Traffic signal countdown timers lead to improved driver responses. More information: S Farzad Ahmadi et al. Latent heat of traffic moving from rest, New Journal of Physics (2017).",https://phys.org/news/2017-11-buffer-bumper-contradicts-traffic-tailgating.html?utm_campaign=awesummly&utm_source=awesummly
107,11 stars seen forming close to Milky Way's black hole,"Astronomers using the Chile-based ALMA telescopes have spotted signs of eleven low-mass stars forming within three light-years to the Milky Way's supermassive black hole. Astronomers called the findings ""genuinely surprising"" as at this distance, it is believed that the black hole's gravitational pull should be strong enough to rip apart clouds of dust and gas before they can form stars.","At the center of our galaxy, in the immediate vicinity of its supermassive black hole, is a region wracked by powerful tidal forces and bathed in intense ultraviolet light and X-ray radiation. These harsh conditions, astronomers surmise, do not favor star formation, especially low-mass stars like our sun. Surprisingly, new observations from the Atacama Large Millimeter/submillimeter Array (ALMA) suggest otherwise. ALMA has revealed the telltale signs of eleven low-mass stars forming perilously close-within three light-years-to the Milky Way's supermassive black hole, known to astronomers as Sagittarius A* . At this distance, tidal forces driven by the supermassive black hole should be energetic enough to rip apart clouds of dust and gas before they can form stars. The presence of these newly discovered protostars suggests that the conditions necessary to birth low-mass stars may exist even in one of the most turbulent regions of our galaxy and possibly in similar locales throughout the universe. The results are published in the Astrophysical Journal Letters. This is a genuinely surprising result and one that demonstrates just how robust star formation can be, even in the most unlikely of places. The ALMA data also suggest that these protostars are about 6,000 years old. This is important because it is the earliest phase of star formation we have found in this highly hostile environment, Yusef-Zadeh said. The team of researchers identified these protostars by seeing the classic double lobes of material that bracket each of them. These cosmic hourglass-like shapes signal the early stages of star formation. Molecules, like carbon monoxide (CO), in these lobes glow brightly in millimeter-wavelength light, which ALMA can observe with remarkable precision and sensitivity. Protostars form from interstellar clouds of dust and gas. Dense pockets of material in these clouds collapse under their own gravity and grow by accumulating more and more star-forming gas from their parent clouds. A portion of this infalling material, however, never makes it onto the surface of the star. Instead, it is ejected as a pair of high-velocity jets from the protostar's north and south poles. Extremely turbulent environments can disrupt the normal procession of material onto a protostar, while intense radiation-from massive nearby stars and supermassive black holes-can blast away the parent cloud, thwarting the formation of all but the most massive of stars. The Milky Way's galactic center, with its 4 million solar mass black hole, is located approximately 26,000 light-years from Earth in the direction of the constellation Sagittarius. Vast stores of interstellar dust obscure this region, hiding it from optical telescopes. Radio waves, including the millimeter and submillimeter light that ALMA sees, are able to penetrate this dust, giving radio astronomers a clearer picture of the dynamics and content of this hostile environment. Prior ALMA observations of the region surrounding Sgr A* by Yusef-Zadeh and his team revealed multiple massive infant stars that are estimated to be about 6 million years old. These objects, known as proplyds, are common features in more placid star-forming regions, like the Orion Nebula. Though the galactic center is a challenging environment for star formation, it is possible for particularly dense cores of hydrogen gas to cross the necessary threshold and forge new stars. The new ALMA observations, however, revealed something even more remarkable, signs that eleven low-mass protostars are forming within 1 parsec - a scant 3 light-years - of the galaxy's central black hole. Yusef-Zadeh and his team used ALMA to confirm that the masses and momentum transfer rates - the ability of the protostar jets to plow through surrounding interstellar material - are consistent with young protostars found throughout the disk of our galaxy. This discovery provides evidence that star formation is taking place within clouds surprisingly close to Sagittarius A*, said Al Wootten with the National Radio Astronomy Observatory in Charlottesville, Virginia, and co-author on the paper. Though these conditions are far from ideal, we can envision several pathways for these stars to emerge. For this to occur, outside forces would have to compress the gas clouds near the center of our galaxy to overcome the violent nature of the region and allow gravity to take over and form stars. The astronomers speculate that high-velocity gas clouds could aid in star formation as they force their way through the interstellar medium. It is also possible that jets from the black hole itself could be plowing into the surrounding gas clouds, compressing material and triggering this burst of star formation. If so, it's likely that planets will eventually form from this material, as is the case for young stars in the galactic disk. Explore further: ALMA detects signs of star formation surprisingly close to galaxy's supermassive black hole. More information: F Yusef-Zadeh et al. ALMA Detection of Bipolar Outflows: Evidence for Low-mass Star Formation within 1 pc of Sgr A*, The Astrophysical Journal (2017).",https://phys.org/news/2017-11-alma-infant-stars-surprisingly-galaxy.html?utm_campaign=awesummly&utm_source=awesummly
108,World's smallest fidget spinner made smaller than hair width,"US-based researchers have developed the world's smallest fidget spinner, measuring one-tenth of a millimetre, which is smaller than the width of a human hair. The team used a 3D printer which uses a laser to convert liquid into a solid. The Nanoscribe machine that built the fidget spinner is also used for making microfluidic and micromechanical devices for scientific applications.","One drop of liquid, a cutting-edge laser 3-D-printer and a few hours are all it takes to make a fidget spinner smaller than the width of a human hair. The tiny whirligig was created by researchers at Oak Ridge National Laboratory's Center for Nanophase Materials Sciences to illustrate the facility's unique resources and expertise available to scientists across the world. The microscale fidget spinner measures only 100 microns wide, or one tenth of a millimeter, but the capabilities it represents are enormous. We felt like it would be an interesting demonstration for younger people who may not know that the federal government maintains these user facilities around the country, which anybody can use as long as they submit a successful proposal, said ORNL's Adam Rondinone. The Nanoscribe machine that built the fidget spinner is also used by researchers to create microfluidic and micromechanical devices for scientific applications. The instrument uses a focused laser to convert a liquid into a solid at a microscopic level. This process, much like 3-D printing, allows researchers to precisely design and build complex designs to make functional microscale devices with moving components. More than 650 researchers used CNMS resources last year to conduct wide-ranging experiments in nanomaterials synthesis; nanofabrication; imaging, microscopy and characterization; and theory, modeling and simulation. CNMS is a Department of Energy Office of Science User Facility. Our job is to offer cutting-edge experiments, instrumentation and expertise, to help other scientists to achieve their goals, Rondinone said. All the tools at CNMS are available through the facility's user program, which is open to users from academia, the private sector, and research institutes worldwide. Access is free of charge to users who publish the results in the open literature. Because of this, Rondinone explains, researchers at companies may be less aware of the resources available to them, or hesitant to use them. We work with industrial partners to help them identify fundamental science questions that we can answer and then publish in open literature, without jeopardizing their intellectual property, he said. The team plans to build an interactive microscopic fidget spinner exhibit as part of ORNL's Traveling Science Fair. It's a compelling way for us to reach out to the next generation of scientists, Rondinone said. Explore further: Japan gives world-beating fidget spinner a whirl.",https://phys.org/news/2017-11-world-smallest-fidget-spinner-showcases.html?utm_campaign=awesummly&utm_source=awesummly
109,US physicists create most advanced quantum simulator ever,"Researchers at the University of Maryland have designed a quantum simulator composed up to 53 qubits, the basic unit of information for quantum computers, using ytterbium ions. While classical computers use bits, which can store either 0 or 1, quantum simulators use qubits, which can store superposed states like 00, 01, 10, 11, to simulate complex interactions between particles.","Two independent teams of scientists, including one from the University of Maryland (UMD) and the National Institute of Standards and Technology (NIST), have used more than 50 interacting atomic qubits to mimic magnetic quantum matter, blowing past the complexity of previous demonstrations. The results appear in this week's issue of Nature. As the basis for its quantum simulation, the UMD-NIST team deploys up to 53 individual ytterbium ions-charged atoms trapped in place by gold-coated and razor-sharp electrodes. A complementary design by Harvard and MIT researchers uses 51 uncharged rubidium atoms confined by an array of laser beams. With so many qubits these quantum simulators are on the cusp of exploring physics that is unreachable by even the fastest modern supercomputers. And adding even more qubits is just a matter of lassoing more atoms into the mix. Each ion qubit is a stable atomic clock that can be perfectly replicated, says UMD team lead Christopher Monroe, who is also the co-founder and chief scientist at the startup IonQ Inc They are effectively wired together with external laser beams. This means that the same device can be reprogrammed and reconfigured, from the outside, to adapt to any type of quantum simulation or future quantum computer application that comes up. Monroe has been one of the early pioneers in quantum computing and his research group's quantum simulator is part of a blueprint for a general-purpose quantum computer. Quantum hardware for a quantum problem. While modern, transistor-driven computers are great for crunching their way through many problems, they can screech to a halt when dealing with more than 20 interacting quantum objects. That's certainly the case for quantum magnetism, in which the interactions can lead to magnetic alignment or to a jumble of competing interests at the quantum scale. What makes this problem hard is that each magnet interacts with all the other magnets, says UMD research scientist Zhexuan Gong, lead theorist and co-author on the study. With the 53 interacting quantum magnets in this experiment, there are over a quadrillion possible magnet configurations, and this number doubles with each additional magnet. Simulating this large-scale problem on a conventional computer is extremely challenging, if at all possible. When these calculations hit a wall, a quantum simulator may help scientists push the envelope on difficult problems. This is a restricted type of quantum computer that uses qubits to mimic complex quantum matter. Qubits are isolated and well-controlled quantum systems that can be in a combination of two or more states at once. Qubits come in different forms, and atoms-the versatile building blocks of everything-are one of the leading choices for making qubits. In recent years, scientists have controlled 10 to 20 atomic qubits in small-scale quantum simulations. Currently, tech industry behemoths, startups and university researchers are in a fierce race to build prototype quantum computers that can control even more qubits. But qubits are delicate and must stay isolated from the environment to protect the device's quantum nature. With each added qubit this protection becomes more difficult, especially if qubits are not identical from the start, as is the case with fabricated circuits. This is one reason that atoms are an attractive choice that can dramatically simplify the process of scaling up to large-scale quantum machinery. Unlike the integrated circuitry of modern computers, atomic qubits reside inside of a room-temperature vacuum chamber that maintains a pressure similar to outer space. The principles of quantum computing differ radically from those of conventional computing, so there's no reason to expect that these two technologies will look anything alike, says Monroe. In the 53-qubit simulator, the ion qubits are made from atoms that all have the same electrical charge and therefore repel one another. But as they push each other away, an electric field generated by a trap forces them back together. The two effects balance each other, and the ions line up single file. Physicists leverage the inherent repulsion to create deliberate ion-to-ion interactions, which are necessary for simulating of interacting quantum matter. The quantum simulation begins with a laser pulse that commands all the qubits into the same state. Then, a second set of laser beams interacts with the ion qubits, forcing them to act like tiny magnets, each having a north and south pole. The team does this second step suddenly, which jars the qubits into action. They feel torn between two choices, or phases, of quantum matter. As magnets, they can either align their poles with their neighbors to form a ferromagnet or point in random directions yielding no magnetization. The physicists can change the relative strengths of the laser beams and observe which phase wins out under different laser conditions. The entire simulation takes only a few milliseconds. By repeating the process many times and measuring the resulting states at different points during the simulation, the team can see the process as it unfolds from start to finish. The researchers observe how the qubit magnets organize as different phases form, dynamics that the authors say are nearly impossible to calculate using conventional means when there are so many interactions. This quantum simulator is suitable for probing magnetic matter and related problems. But other kinds of calculations may need a more general quantum computer with arbitrarily programmable interactions in order to get a boost. Quantum simulations are widely believed to be one of the first useful applications of quantum computers, says Alexey Gorshkov, NIST theoretical physicist and co-author of the study. After perfecting these quantum simulators, we can then implement quantum circuits and eventually quantum-connect many such ion chains together to build a full-scale quantum computer with a much wider domain of applications. As they look to add even more qubits, the team believes that its simulator will embark on more computationally challenging terrain, beyond magnetism. At that point, we can potentially explore difficult problems in quantum chemistry or materials design. Explore further: Quantum computing on the move. More information: J Zhang et al, Observation of a many-body dynamical phase transition with a 53-qubit quantum simulator, Nature (2017).",https://phys.org/news/2017-11-quantum-simulators-wield-qubits.html?utm_campaign=awesummly&utm_source=awesummly
110,"Deepest fish collected from 8,000 metres below sea level","Researchers have collected snailfish from depths of about 6,900-8,000 metres along the Mariana Trench in the Pacific, making it the deepest fish collected from the ocean floor. The new species named Mariana snailfish, can live under water pressures equivalent to an elephant standing on a thumb, said researchers. The scale-less translucent snailfish are said to feed on crustaceans and shrimp.","The ocean's deepest fish doesn't look like it could survive in harsh conditions thousands of feet below the surface. Instead of giant teeth and a menacing frame, the fishes that roam in the deepest parts of the ocean are small, translucent, bereft of scales - and highly adept at living where few other organisms can. Meet the deepest fish in the ocean, a new species named the Mariana snailfish by an international team of researchers that discovered it. The Mariana snailfish thrives at depths of up to about 8,000 meters (26,200 feet) along the Mariana Trench near Guam. The team published a paper describing the new species this week in the journal Zootaxa. This is the deepest fish that's been collected from the ocean floor, and we're very excited to have an official name, said lead author Mackenzie Gerringer, a postdoctoral researcher at the University of Washington's Friday Harbor Laboratories. They don't look very robust or strong for living in such an extreme environment, but they are extremely successful. Snailfish are found at many different depths in marine waters around the world, including off the coast of San Juan Island, where Gerringer is continuing research on the family of fish. In deep water, they cluster together in groups and feed on tiny crustaceans and shrimp using suction from their mouths to gulp prey. Little is known about how these fish can live under intense water pressure; the pressure at those depths is similar to an elephant standing on your thumb. Video courtesy of SOI/HADES/University of Aberdeen This new species appears to dominate parts of the Mariana Trench, the deepest stretch of ocean in the world that is located in the western Pacific Ocean. DNA analysis and 3-D scanning to analyze skeletal and tissue structures helped researchers determine they had found a new species. Snailfishes have adapted to go deeper than other fish and can live in the deep trenches. There are lots of invertebrate prey and the snailfish are the top predator. They are active and look very well-fed. A handful of researchers have explored the Mariana Trench, but few comprehensive surveys of the trench and its inhabitants have been completed because of its depth and location, Gerringer explained. These research trips, conducted while Gerringer completed her doctorate at University of Hawai'i at Manoa, involved dropping traps with cameras down to the bottom of the trench. It can take four hours for a trap to sink to the bottom. After waiting an additional 12 to 24 hours, the researchers sent an acoustic signal to the trap, which then released weights and rose to the surface with the help of flotation. That allowed scientists to catch fish specimens and take video footage of life at the bottom of the ocean. There are a lot of surprises waiting, Gerringer said. It's amazing to see what lives there. We think of it as a harsh environment because it's extreme for us, but there's a whole group of organisms that are very happy down there. Footage from the 2014 research cruise on R/V Falkor will also run in the BBC's Blue Planet II series, which is now airing in the UK The research team also filmed another new species on this cruise, the ethereal snailfish, living at great depths in the Mariana Trench. The Mariana snailfish's location was its most distinguishing characteristic, but researchers also saw a number of differences in physiology and body structure that made it clear they had found a new species. With the help of a CT scanner at the UW's Friday Harbor Laboratories, the researchers could look in close digital detail to study elements of the fish. The authors acknowledge the broad collaboration needed for deep-sea science, particularly in this discovery, and decided the new fish's scientific name should reflect that collaborative effort. The fish is named after a sailor, Herbert Swire, an officer on the HMS Challenger expedition in the late 1800s that first discovered the Mariana Trench. Other co-authors are Alan Jamieson of Newcastle University, and Erica Goetze and Jeffrey Drazen of the University of Hawai'i at Manoa. The research was funded by the National Science Foundation, Schmidt Ocean Institute, and the Marine Alliance for Science and Technology for Scotland. Note that Linley is based in the UK and GMT time zone.",http://www.washington.edu/news/2017/11/28/theres-a-deeper-fish-in-the-sea/?utm_campaign=awesummly&utm_source=awesummly
111,Single telescope discovers 72 new galaxies,"Astronomers have discovered 72 galaxies using ESO's Very Large Telescope (VLT) in Chile as part of the deepest spectroscopic survey ever conducted. VLT used an instrument which split light into its component colours to create a spectrum. This allows measurement of distance, colours and other properties of galaxies which went undetected even by NASA's Hubble Space Telescope, said astronomers.","Astronomers using the MUSE instrument on ESO's Very Large Telescope in Chile have conducted the deepest spectroscopic survey ever. They focused on the Hubble Ultra Deep Field, measuring distances and properties of 1600 very faint galaxies including 72 galaxies that have never been detected before, even by Hubble itself. This groundbreaking dataset has already resulted in 10 science papers that are being published in a special issue of Astronomy & Astrophysics. This wealth of new information is giving astronomers insight into star formation in the early Universe, and allows them to study the motions and other properties of early galaxies - made possible by MUSE's unique spectroscopic capabilities. This resulted in the deepest spectroscopic observations ever made; precise spectroscopic information was measured for 1600 galaxies, ten times as many galaxies as has been painstakingly obtained in this field over the last decade by ground-based telescopes. The original HUDF images were pioneering deep-field observations with the NASA/ESA Hubble Space Telescope published in 2004. They probed more deeply than ever before and revealed a menagerie of galaxies dating back to less than a billion years after the Big Bang. The area was subsequently observed many times by Hubble and other telescopes, resulting in the deepest view of the Universe to date. Now, despite the depth of the Hubble observations, MUSE has - among many other results - revealed 72 galaxies never seen before in this very tiny area of the sky. Roland Bacon takes up the story: MUSE can do something that Hubble can't - it splits up the light from every point in the image into its component colours to create a spectrum. This allows us to measure the distance, colours and other properties of all the galaxies we can see - including some that are invisible to Hubble itself. The MUSE data provides a new view of dim, very distant galaxies, seen near the beginning of the Universe about 13 billion years ago. It has detected galaxies 100 times fainter than in previous surveys, adding to an already richly observed field and deepening our understanding of galaxies across the ages. The survey unearthed 72 candidate galaxies known as Lyman-alpha emitters that shine only in Lyman-alpha light. Current understanding of star formation cannot fully explain these galaxies, which just seem to shine brightly in this one colour. Because MUSE disperses the light into its component colours these objects become apparent, but they remain invisible in deep direct images such as those from Hubble. We learn things about these galaxies that is only possible with spectroscopy, such as chemical content and internal motions - not galaxy by galaxy but all at once for all the galaxies! Another major finding of this study was the systematic detection of luminous hydrogen halos around galaxies in the early Universe, giving astronomers a new and promising way to study how material flows in and out of early galaxies. Remarkably, these data were all taken without the use of MUSE's recent Adaptive Optics Facility upgrade. The activation of the AOF after a decade of intensive work by ESO's astronomers and engineers promises yet more revolutionary data in the future, concludes Roland Bacon. The Hubble Ultra Deep Field is one of the most extensively studied areas of space. To date, 13 instruments on eight telescopes, including the ESO-partnered ALMA (eso1633), have observed the field from X-ray to radio wavelengths. The negatively-charged electrons that orbit the positively-charged nucleus in an atom have quantised energy levels. That is, they can only exist in specific energy states, and they can only transition between them by gaining or losing precise amounts of energy. Lyman-alpha radiation is produced when electrons in hydrogen atoms drop from the second-lowest to the lowest energy level. The precise amount of energy lost is released as light with a particular wavelength in the ultraviolet part of the spectrum, which astronomers can detect with space telescopes or on Earth in the case of redshifted objects. For this data, at redshift of z ~ 3-6.6, the Lyman-alpha light is seen as visible or near-infrared light. The Adaptive Optics Facility with MUSE has already revealed previously unseen rings around the planetary nebula IC 4406 (eso1724). This research was presented in a series of 10 papers to appear in the journal Astronomy & Astrophysics. ESO is the foremost intergovernmental astronomy organisation in Europe and the world's most productive ground-based astronomical observatory by far. ESO carries out an ambitious programme focused on the design, construction and operation of powerful ground-based observing facilities enabling astronomers to make important scientific discoveries. ESO also plays a leading role in promoting and organising cooperation in astronomical research. ESO operates three unique world-class observing sites in Chile: La Silla, Paranal and Chajnantor. At Paranal, ESO operates the Very Large Telescope, the world's most advanced visible-light astronomical observatory and two survey telescopes. VISTA works in the infrared and is the world's largest survey telescope and the VLT Survey Telescope is the largest telescope designed to exclusively survey the skies in visible light. ESO is a major partner in ALMA, the largest astronomical project in existence. Lyon Centre for Astrophysics Research (CRAL). Cell: +33 6 08 9 14 27. Cell: +31 6 50 92 51 89. Cell: +49 160 24 34 574. Institut de Recherche en Astrophysique et Planetologie. Cell: +33 6 62 64 12 68. Connect with ESO on social media.",https://www.eso.org/public/news/eso1738/?utm_campaign=awesummly&utm_source=awesummly
112,"Big Bang never happened, claims new research","Contrary to the most accepted theory of Universe starting from a Big Bang, Brazil-based physicist Juliano Neves has reintroduced the theory of ""bouncing Universe"", which states the current expansion was preceded by contraction. Neves suggested, ""there may be remains of black holes in the ongoing expansion that date from contraction phase and passed intact through the bottleneck of the bounce.""","In a study recently published in the journal General Relativity and Gravitation, Neves suggests the elimination of a key aspect of the standard cosmological model: the need for a spacetime singularity known as the Big Bang. In raising this possibility, Neves challenges the idea that time had a beginning and reintroduces the possibility that the current expansion was preceded by contraction. Moreover, the switch from contraction to expansion may not have destroyed all traces of the preceding phase. Who knows, there may be remains of black holes in the ongoing expansion that date from the prior contraction phase and passed intact through the bottleneck of the bounce, Neves told Agencia FAPESP. It is precisely in black holes that Neves locates the starting point for his investigations into what he calls the bouncing Universe, in which contraction is followed by expansion. The inspiration for the bouncing Universe came from a mathematical trick to avoid the formation of singularities in black holes, he said. There are two kinds of singularity in the Universe. Black holes are the most mysterious cosmic objects. A black hole consists of the imploded core remaining after a giant star explodes. The core contracts to form a singularity, a point with infinite density and the strongest gravitational attraction known to exist. Nothing escapes from it, not even light. The singularity is located at the center of the black hole, hidden behind the event horizon, a membrane that indicates the point of no return from which nothing escapes the inexorable destiny of being swallowed up and destroyed by the singularity. But not all black holes have to contain a singularity. There are no singularities in so-called regular black holes, Neves said. In 1968, US physicist James Bardeen used a mathematical trick to modify the solution to the general relativity equations that describe black holes. The trick consisted of thinking of the mass of a black hole not as a constant, as had previously been the case, but as a function that depends on the distance to the center of the black hole. With this change, a different black hole, termed a regular black hole, emerged from the solution to the equations. What defines a black hole isn't a singularity but an event horizon, Neves said. Outside the event horizon of a regular black hole, there are no major changes, but inside it, the changes are deep-seated. There's a different spacetime that avoids the formation of a singularity. Regular black holes are permitted, since they don't violate general relativity. The concept isn't new and has frequently been revisited in recent decades. In order to measure the rate at which the Universe is expanding with the standard cosmology, the model in which there's a Big Bang, a mathematical function is used that depends only on cosmological time, Neves explained. This is where the mathematical trick comes in. Neves and his postdoctoral supervisor Alberto Vazques Saa, Full Professor at IMECC-UNICAMP, introduced a scale factor that makes the rate at which the Universe is expanding depend not only on time but also on cosmological scale into the solutions to the general relativity equations that describe the geometry of the cosmos. This is the proposal presented in the recently published article, which is part of the Thematic Project Physics and geometry of spacetime, with Saa as principal investigator. Neves's postdoctoral research was supported by a scholarship from FAPESP. It ceases to be a necessary condition for the cosmos to begin universal expansion. Eliminating the singularity or Big Bang brings back the bouncing Universe on to the theoretical stage of cosmology. The absence of a singularity at the start of spacetime opens up the possibility that vestiges of a previous contraction phase may have withstood the phase change and may still be with us in the ongoing expansion of the Universe, Neves said. Today, we know the theory of general relativity permits a non-singular cosmology, with no Big Bang, at least in theory. In modern science, a theory is worthless if cannot be verified, however beautiful and inspiring it may be. The candidates include remnants of black holes from a previous phase of universal contraction that may have survived the bounce, Neves said. The Big Bang theory began to be formulated in the late 1920s, when US astronomer Edwin Hubble discovered that almost all galaxies are moving away from each other at ever-faster velocities. This means they were much closer together in the remote past. More precisely, 13.8 billion years ago all the matter and energy in the Universe were compressed into an initial state with infinite density and temperature, where the traditional laws of physics no longer apply. To define this state cosmologists paradoxically borrowed the concept of singularity from mathematics, where it refers to indefinition. In this case, there was a primordial cosmological singularity that began expanding 13.8 billion years ago. The hundreds of billions of galaxies in the cosmos were formed from the matter and energy ejected by this initial explosion. Guided by Einstein's theory of general relativity, which is used to explain cosmic phenomena, from the 1940s onward, scientists constructed a detailed model of the evolution of the Universe since the Big Bang. The model was based on the assumption that the expansion might eventually decelerate in response to the gravitational attraction exerted by the mass of the Universe. This image of an eternal succession of universes with alternating expansion and contraction phases was called the cyclical Universe, which derives from bouncing cosmologies, Neves said.",http://agencia.fapesp.br/before_the_big_bang/26684/?utm_campaign=awesummly&utm_source=awesummly
113,Discovery of AIDS-causing virus HIV won Nobel Prize in 2008,"The human immunodeficiency virus (HIV) which lowers the body's ability to fight off infections leading to acquired immune deficiency syndrome (AIDS), was discovered by French researchers FranÃ§oise BarrÃ©-Sinoussi and Luc Montagnier in 1984. Their work partially explained how HIV attacks body's T-cells, essential for immunity, and won them the 2008 Nobel Prize in Physiology or Medicine.","Harald zur Hausen, Francoise Barre-Sinoussi, Luc Montagnier Share this: 6 October 2008 The Nobel Assembly at Karolinska Institutet has today decided to award. The Nobel Prize in Physiology or Medicine for 2008 with one half to. For his discovery of human papilloma viruses causing cervical cancer and the other half jointly to. This year's Nobel Prize awards discoveries of two viruses causing severe human diseases. Harald zur Hausen went against current dogma and postulated that oncogenic human papilloma virus (HPV) caused cervical cancer, the second most common cancer among women. He realized that HPV-DNA could exist in a non-productive state in the tumours, and should be detectable by specific searches for viral DNA. He found HPV to be a heterogeneous family of viruses. Only some HPV types cause cancer. His discovery has led to characterization of the natural history of HPV infection, an understanding of mechanisms of HPV-induced carcinogenesis and the development of prophylactic vaccines against HPV acquisition. Francoise Barre-Sinoussi and Luc Montagnier discovered human immunodeficiency virus (HIV). Virus production was identified in lymphocytes from patients with enlarged lymph nodes in early stages of acquired immunodeficiency, and in blood from patients with late stage disease. They characterized this retrovirus as the first known human lentivirus based on its morphological, biochemical and immunological properties. HIV impaired the immune system because of massive virus replication and cell damage to lymphocytes. The discovery was one prerequisite for the current understanding of the biology of the disease and its antiretroviral treatment. He assumed that the tumour cells, if they contained an oncogenic virus, should harbour viral DNA integrated into their genomes. The HPV genes promoting cell proliferation should therefore be detectable by specifically searching tumour cells for such viral DNA. Harald zur Hausen pursued this idea for over 10 years by searching for different HPV types, a search made difficult by the fact that only parts of the viral DNA were integrated into the host genome. He found novel HPV-DNA in cervix cancer biopsies, and thus discovered the new, tumourigenic HPV16 type in 1983. In 1984, he cloned HPV16 and 18 from patients with cervical cancer. The HPV types 16 and 18 were consistently found in about 70% of cervical cancer biopsies throughout the world. The global public health burden attributable to human papilloma viruses is considerable. More than 5% of all cancers worldwide are caused by persistent infection with this virus. Infection by the human papilloma virus is the most common sexually transmitted agent, afflicting 50-80% of the population. Of the more than 100 HPV types known, about 40 infect the genital tract, and 15 of these put women at high risk for cervical cancer. In addition, HPV is found in some vulval, penile, oral and other cancers. Human papilloma virus can be detected in 99.7% of women with histologically confirmed cervical cancer, affecting some 500,000 women per year. Harald zur Hausen demonstrated novel properties of HPV that have led to an understanding of mechanisms for papilloma virus-induced carcinogenesis and the predisposing factors for viral persistence and cellular transformation. He made HPV16 and 18 available to the scientific community. Vaccines were ultimately developed that provide >=95 % protection from infection by the high risk HPV16 and 18 types. The vaccines may also reduce the need for surgery and the global burden of cervical cancer. Following medical reports of a novel immunodeficiency syndrome in 1981, the search for a causative agent was on. Francoise Barre-Sinoussi and Luc Montagnier isolated and cultured lymph node cells from patients that had swollen lymph nodes characteristic of the early stage of acquired immune deficiency. They detected activity of the retroviral enzyme reverse transcriptase, a direct sign of retrovirus replication. They also found retroviral particles budding from the infected cells. Isolated virus infected and killed lymphocytes from both diseased and healthy donors, and reacted with antibodies from infected patients. In contrast to previously characterized human oncogenic retroviruses, the novel retrovirus they had discovered, now known as human immunodeficiency virus (HIV), did not induce uncontrolled cell growth. Instead, the virus required cell activation for replication and mediated cell fusion of T lymphocytes. This partly explained how HIV impairs the immune system since the T cells are essential for immune defence. The significance of their achievements should be viewed in the context of a global ubiquitous epidemic affecting close to 1% of the population. Soon after the discovery of the virus, several groups contributed to the definitive demonstration of HIV as the cause of acquired human immunodeficiency syndrome (AIDS). Barre-Sinoussi and Montagnier's discovery made rapid cloning of the HIV-1 genome possible. This has allowed identification of important details in its replication cycle and how the virus interacts with its host. Furthermore, it led to development of methods to diagnose infected patients and to screen blood products, which has limited the spread of the pandemic. The unprecedented development of several classes of new antiviral drugs is also a result of knowledge of the details of the viral replication cycle. The combination of prevention and treatment has substantially decreased spread of the disease and dramatically increased life expectancy among treated patients. The cloning of HIV enabled studies of its origin and evolution. The virus was probably passed to humans from chimpanzees in West Africa early in the 20th century, but it is still unclear why the epidemic spread so dramatically from 1970 and onwards. Identification of virus-host interactions has provided information on how HIV evades the host's immune system by impairing lymphocyte function, by constantly changing and by hiding its genome in the host lymphocyte DNA, making its eradication in the infected host difficult even after long-term antiviral treatment. Extensive knowledge about these unique viral host interactions has, however, generated results that can provide ideas for future vaccine development as well as for therapeutic approaches targeting viral latency. HIV has generated a novel pandemic. Never before has science and medicine been so quick to discover, identify the origin and provide treatment for a new disease entity. Successful anti-retroviral therapy results in life expectancies for persons with HIV infection now reaching levels similar to those of uninfected people. Professor emeritus and former Chairman and Scientific Director, German Cancer Research Centre, Heidelberg, Germany. Professor emeritus and Director, World Foundation for AIDS Research and Prevention, Paris, France.",https://www.nobelprize.org/nobel_prizes/medicine/laureates/2008/press.html?utm_campaign=awesummly&utm_source=awesummly
114,Copy of Golden Record sent outside Solar System now on sale,"Copies of Golden Record, which is on-board the only spacecraft to exit the Solar System and go into interstellar space, are going on sale as vinyl and audio CDs. The record, carried by NASA's Voyager 1, features 'The Sounds of Earth', 'Greetings in 55 Languages', Chuck Berry's 'Johnny B Goode' and 'Jaat Kahan Ho' by Indian artist Kesarbai Kerkar.","Astronomer and science educator Carl Sagan chaired the Voyager Interstellar Record Committee that created this object, which is both an inspired scientific effort and a compelling piece of conceptual art. Natural sounds-birds, a train, a baby's cry, a kiss-are collaged into a lovely audio poem called Sounds of Earth. There are spoken greetings in dozens of human languages-and one whale language-and more than 100 images encoded in analog that depict who, and what, we are. In 1977, NASA launched two spacecraft, Voyager 1 and 2, on a grand tour of the solar system and into the mysteries of interstellar space. Attached to each of these probes is a beautiful golden record containing a message for any extraterrestrial intelligence that might encounter it, perhaps billions of years from now. This enchanting artifact, officially called the Voyager Interstellar Record, may be the last vestige of our civilization after we are gone forever. As we embarked on our own Kickstarter project to make the golden record available on vinyl for the first time, in celebration of Voyager's 40th anniversary, we realized that we saw the original artifact through three different lenses. As an exquisitely curated music compilation, the Voyager record is an inviting port of entry to unfamiliar yet entrancing sounds from other cultures and other times. As an objet d'art and design, it represents deep insights about communication, context, and the power of media. In the realm of science, it raises fundamental questions about who we are and our place in the universe. At the intersection of those three perspectives, the Voyager record is a testament to the potential of science and art to ignite humanity's sense of curiosity and wonder. As of this writing, it's almost 21 billion kilometers away from Earth. Speeding along at 17 kilometers per second, it will take another 40,000 years before the spacecraft passes within 1.6 light-years of a star in the constellation Camelopardalis. The slightly slower Voyager 2 is at the outermost edge of our solar system, where the sun's plasma wind blows against cosmic dust and gas. Soon, it too will venture into interstellar space. We may never know whether an extraterrestrial civilization ever listens to the golden record. It was a gift from humanity to the cosmos. The record embodies a sense of possibility and hope. And it's as relevant now as it was in 1977. The Voyager Interstellar Record is a reminder of what we can achieve when we are at our best-and that our future really is up to all of us.",http://www.ozmarecords.com/voyager?utm_campaign=awesummly&utm_source=awesummly
115,Monkeys learn to control robotic arm with their minds,US-based neuroscientists have demonstrated how amputees can learn to control a robotic arm through electrodes implanted in the brain using three rhesus monkeys with amputated arms. The team found neural connections grew stronger over time when implants were placed on the side of the brain opposite to the amputated limb and also when the implant was on the same side.,"A new study by neuroscientists at the University of Chicago shows how amputees can learn to control a robotic arm through electrodes implanted in the brain. The research, published in Nature Communications, details changes that take place in both sides of the brain used to control the amputated limb and the remaining, intact limb. The results show both areas can create new connections to learn how to control the device, even several years after an amputation. But what was also interesting was the brain's plasticity over long-term exposure, and seeing what happened to the connectivity of the network as they learned to control the device. Previous experiments have shown how paralyzed human patients can move robotic limbs through a brain machine interface. The new study is one of the first to test the viability of these devices in amputees as well. The researchers worked with three rhesus monkeys who suffered injuries at a young age and had to have an arm amputated to rescue them four, nine and 10 years ago, respectively. Their limbs were not amputated for the purposes of the study. In two of the animals, the researchers implanted electrode arrays in the side of the brain opposite, or contralateral, to the amputated limb. In the third animal, the electrodes were implanted on the same side, or ipsilateral, to the amputated limb. This is the side that still controlled the intact limb. The monkeys were then trained to move a robotic arm and grasp a ball using only their thoughts. The scientists recorded the activity of neurons where the electrodes were placed, and used a statistical model to calculate how the neurons were connected to each other before the experiments, during training and once the monkeys mastered the activity. The connections between neurons on the contralateral side-the side that had been controlling the amputated arm-were sparse before the training, most likely because they had not been used for that function in a long time. But as training progressed, these connections became more robust and dense in areas used for both reaching and grasping. On the ipsilateral side-the side that had been controlling the monkey's intact arm-the connections were dense at the beginning of the experiments. But the researchers saw something interesting as training progressed: first the connections were pruned and the networks thinned, before rebuilding into a new, dense network. But after a few days it started rebuilding into a new network that can control both the intact limb and the neuroprosthetic. Now the team plans to continue their work by combining it with research by other groups to equip neuroprosthetic limbs with sensory feedback about touch and proprioception, which is the sense of where the limb is located in space. That's how we can begin to create truly responsive neuroprosthetic limbs, when people can both move it and get natural sensations through the brain machine interface, Hatsopoulos said. The study, Changes in Cortical Network Connectivity with Long-term Brain-Machine Interface Exposure after Chronic Amputation, was published on November 27, 2017.",https://sciencelife.uchospitals.edu/2017/11/27/amputees-can-learn-to-control-a-robotic-arm-with-their-minds/?utm_campaign=awesummly&utm_source=awesummly
116,Scientists make transparent material absorb light,"A group of physicists from Russia, Sweden, and the US has demonstrated a material with no light-absorbing capacity to ""virtually"" absorb light. Scientists found the transparent layer neither transmitted nor reflected incident electromagnetic radiation when its intensity was exponentially increased. However, when the exponential growth was halted, the energy locked in the layer was released.","A group of physicists from Russia, Sweden and the US has demonstrated a highly unusual optical effect. They managed to virtually absorb light using a material that has no light-absorbing capacity. The research findings, published in Optica, break new ground for the creation of memory elements for light. The absorption of electromagnetic radiation, including light, is one of the main effects of electromagnetism. This process takes place when electromagnetic energy is converted to heat or another kind of energy within an absorbing material. Coal, black paint and carbon nanotube arrays-also known as Vantablack-appear black because they absorb the energy of the incident light almost completely. Other materials, such as glass or quartz, have no absorbing properties and therefore look transparent. In their theoretical research, the results of which were published in the journal Optica, the physicists managed to dispel that simple and intuitive notion by making a completely transparent material appear perfectly absorbing. To achieve that, the researchers employed special mathematical properties of the scattering matrix-a function that relates an incident electromagnetic field with the one scattered by the system. When a light beam of time-independent intensity hits a transparent object, the light is not absorbed, but is scattered by the material-a phenomenon caused by the unitary property of the scattering matrix. In particular, if the intensity growth is exponential, the total incident light energy will accumulate in the transparent material without leaving it. That being the case, the system will appear perfectly absorbent from the outside. To illustrate the effect, the researchers examined a thin layer of a transparent dielectric and calculated the intensity profile required for the absorption of the incident light. The calculations confirmed that when the incident wave intensity grows exponentially, the light is neither transmitted nor reflected. That is, the layer looks perfectly absorbent despite the fact that it lacks the actual absorption capacity. However, when the exponential growth of the incident wave amplitude comes to a halt, the energy locked in the layer is released. Our theoretical findings appear to be rather counterintuitive. Up until we started our research, we couldn't even imagine that it would be possible to pull off such a trick with a transparent structure, says Denis Baranov, a doctoral student at MIPT and one of the authors of the study. However, it was the mathematics that led us to the effect. Who knows, electrodynamics may well harbor other fascinating phenomena. The results of the study not only broaden our general understanding of how light behaves when it interacts with common transparent materials, but also have a wide range of practical applications. To give an example, the accumulation of light in a transparent material may help design optical memory devices that would store optical information without any losses and release it when needed. Explore further: The path length of light in opaque media. More information: Denis G Baranov et al, Coherent virtual absorption based on complex zero excitation for ideal light capturing, Optica (2017).",https://phys.org/news/2017-11-scientists-transparent-materials-absorb.html?utm_campaign=awesummly&utm_source=awesummly
117,Large iceberg breaks off from glacier in southern Chile,"An iceberg measuring 350x380 square-metre has separated from Chile's Grey glacier near the southern tip of South America. Officials at Torres del Paine National Park, home to the glacier, said such ruptures had not occurred since early 1990s. The park, famous for its mountain views, is visited by over 1.15 lakh tourists annually, according to the country's forestry service.","A large iceberg broke off the Grey glacier in southern Chile, authorities said on Tuesday, adding that the cause of the rupture was unclear. Park officials at Chile's Torres del Paine National Park, home to the glacier, said such ruptures were rare and had not occurred since the early 1990s. Dr Ricardo Jana, glaciologist from the Chilean Antarctic Institute, said the iceberg was bigger than expected. This is a situation we had anticipated, but the most singular and anecdotal thing is that it is an iceberg of much larger dimensions, which is notable. Torres del Paine is one of Chile's most popular tourist attractions, famous for its mountain views and visited by more than 115,000 tourists annually, according to Conaf. Grey glacier is located in the Southern Patagonian ice field, just west of the Cordillera del Paine. Before dividing in two at its front end, the glacier is 6km wide and more than 30m high.",https://www.theguardian.com/environment/2017/nov/29/large-iceberg-breaks-off-from-grey-glacier-in-southern-chile?utm_campaign=awesummly&utm_source=awesummly
118,Scientists find methane-fuelled ecosystems in Mexico's caves,"Scientists with the US Geological Survey have found an ecosystem thriving on methane gas in the flooded caves of Mexico's Yucatan Peninsula. Methane, which forms in soils and usually migrates upward, was found to go deeper into the water and caves beneath the jungles. The methane is consumed by bacteria, which then fuel an ecosystem dominated by crustaceans including shrimps.","In the underground rivers and flooded caves of Mexico's Yucatan Peninsula, where Mayan lore described a fantastical underworld, scientists have found a cryptic world in its own right. The research, conducted by scientists who are trained in cave diving in addition to their other expertise, is the most detailed ecological study ever for a coastal cave ecosystem that is always underwater. In fact, the scientists had to use techniques that had previously been used by deep-sea submergence vehicles to be able to study the environment. The opportunity to work with an international team of experts has been a remarkable experience for me, said David Brankovits, who is the paper's lead author and conducted the research during his Ph. Finding that methane and other forms of mostly invisible dissolved organic matter are the foundation of the food web in these caves explains why cave-adapted animals are able to thrive in the water column in a habitat without visible evidence of food. The study was conducted in the Ox Bel Ha cave network of the northeastern Yucatan, which is described as a subterranean estuary because the flooded cave passages contain distinct water layers consisting of freshwater fed by rainfall and salt water from the coastal ocean. This subterranean estuary complex covers an area approximately the size of Galveston Bay, the seventh largest surface estuary in the United States. The freshwater portion of the caves and the sinkholes, which are used to access the caves and are referred to locally as cenotes, are important sources of freshwater for communities throughout the Yucatan. Methane in the caves forms naturally beneath the jungle floor and migrates downward, deeper into the water and caves. Normally, all of the methane formed in soils migrates upward, towards the atmosphere. This sets the stage for the bacteria and other microbes that form the basis for the cave ecosystem. The microbes eat both the methane in the water and other dissolved organic material that the freshwater brought with it from the surface. The microbes then fuel a food web that is dominated by crustaceans, including a cave-adapted shrimp species that obtains about 21 percent of its nutrition from methane. The processes we are investigating in these stratified groundwater systems are analogous to what is happening in the global ocean, especially in oxygen minimum zones where deoxygenation is a growing concern, says John Pohlman, a coauthor of the study and a USGS biogeochemist whose work from the early 90s motivated the research. Although accessing these systems requires specialized training and strict adherence to cave diving safety protocols, relative to the complexity of an oceanographic expedition, the field programs we organize are simple and economical. One surprising finding was how important the dissolved organic material like methane was to the caves' food web. Prior studies had assumed that the majority of organic material that feeds the microbes of caves came from vegetation and other detritus in the tropical forest that washed into the caves from the cenotes. The research was conducted during field expeditions funded by the USGS, TAMUG, the National Autonomous University of Mexico, and with field assistance from Moody Gardens and Speleotech. Data from materials collected during the field program was provided by collaborating researchers from the USGS, the University of Alaska Fairbanks, the University of Basel in Switzerland, and the Woods Hole Oceanographic Institution. USGS involvement was partially supported by the USGS Gas Hydrates Project and USGS Coastal Aquifers Project. The study can be accessed here.",https://www.usgs.gov/news/mexico-s-yucatan-peninsula-reveals-a-cryptic-methane-fueled-ecosystem-flooded-caves?utm_campaign=awesummly&utm_source=awesummly
119,Printable bacteria that can power electronic devices made,"UK-based researchers have used an inkjet printer to print a ""bio-ink"" of cyanobacteria (green) onto a conductive surface, creating a solar cell. Unlike conventional solar cells that operate only in light, cyanobacteria can also generate electricity for small devices in the dark. The cells generated a continuous power output over a 100-hour period of light and dark cycles.","The researchers expect that the cell may serve as an environmentally friendly power supply for low-power devices such as biosensors, and can even be scaled up to print a bioenergy wallpaper. However, even in the dark these organisms continue to generate some energy by metabolizing their internal storage reserves. So when the organisms are connected to a non-biological electrode, they can function as either a bio solar panel when exposed to light or a solar bio-battery in the dark. Typically, the organisms are deposited onto an electrode surface from a bulky liquid reservoir. In the new study, the researchers demonstrated that inkjet printing can be used to print both the carbon nanotube electrode surface and the cyanobacteria on top of it, while allowing the bacteria to remain fully viable. This approach not only allows the cells to be fabricated quickly, but the set-up is also more compact and allows for greater precision in cell design. To demonstrate, the researchers showed that nine connected cells can power a digital clock or generate flashes of light from an LED, illustrating the ability to produce short bursts of relatively high power. The researchers also showed that the cells can generate a continuous power output over the course of a 100-hour period consisting of light and dark cycles. The bioenergy wallpaper is a scaled-up application of our BPV system, Sawa said. The wallpaper will have carbon-based conductive patterns with electron-producing cyanobacteria. It turns an interior surface into an energy harvester to drive low-power applications like LED lights and/or biosensors, which can, for example, monitor indoor air quality. The researchers also expect that the power output of the cells can be improved in a variety of ways, such as by improving circuit conductivity, optimizing cell design, and using more resilient organisms. Explore further: Researchers develop wallpaper bio-solar panel.",https://phys.org/news/2017-11-digitally-cyanobacteria-power-small-electronic.html?utm_campaign=awesummly&utm_source=awesummly
120,Indus civilisation thrived without river: IIT K-led study,"Contrary to current belief, it was the departure of a large Himalayan river, rather than its arrival, that triggered the growth of Indus civilisation, a study led by IIT Kanpur and UK-based researchers has claimed. The team also found evidence that the civilisation thrived in the dried valley with water from seasonal monsoon rivers after Sutlej changed its course.","The Indus or Harappan Civilisation was a Bronze Age society that developed mainly in the northwestern regions of South Asia from 5300 to 3300 years ago, at about the same time as urban civilisations developed in Mesopotamia and Egypt. Archaeological evidence shows that many of the settlements in the Indus Civilisation developed along the banks of a river called the Ghaggar-Hakra in northwest India and Pakistan. It has generally been thought that this was a major Himalayan river that dried up either due to climatic or tectonic changes. A new study, led by researchers from Imperial College London and the Indian Institute of Technology Kanpur, has now provided evidence that a major Himalayan river did not flow at the same time as the development of Indus Civilisation urban settlements. This research shows how ancient urban centres didn't necessarily need an active, flowing river system in order to thrive. Professor Sanjeev Gupta, lead author from Department of Earth Science and Engineering at Imperial, said: The findings challenge our current understanding of how urbanisation in many ancient civilisations began and grew in relation to natural resources. Contrary to current belief, it was the departure of a large river, rather than its arrival, that triggered the growth of Indus urban centres. This meant that three thousand years later, when the Indus people settled the area, there was only an abandoned large river valley occupied by seasonal monsoon river flow instead of a large Himalayan river. The researchers say the time gap between the river shifting course and the Indus Civilisation settlements appearing rules out the existence of a Himalayan-fed river that nourished Indus Civilisation urban settlements along the river channel. The team were also able to pinpoint what the original source of the river sediments had been, showing that the Himalayan Sutlej River had once flowed along the Ghaggar-Hakra dried river channel, or palaeochannel. They found that after the Sutlej River changed course, the scar it left in the landscape acted as a topographic low to capture river flow during the monsoon. This meant that despite not living along a permanent river, the Indus settlements still benefited from a water source. The civilization would also not have been threatened by the risk of devastating floods that living next to a big river brings. To determine the timing of the river, the team drilled cores through the dried Ghaggar-Hakra river bed and analysed the layers of river sediments that had built up over time. To find out when the sediments had been deposited by the river while it was flowing, they dated mineral grains extracted from the sediment, which was carried out at the DTU-Aarhus Riso laboratory in Denmark. When sediments are buried beneath the ground, natural background radiation results in energy being stored in mineral grains such as quartz and feldspar. If the mineral grains are not exposed to light the amount of energy builds up and represents the amount of time since their burial. Scientists can then measure the stored energy in the laboratory and pinpoint when the layers of sediment were buried. This method, called optically stimulated luminescence dating, can therefore tell them when the river last flowed. The team were also able to determine where the original material in the river came from by dating mineral grains such as zircon and mica, revealing the previous course of the river. Most major ancient urban civilisations, such as Egypt and Mesopotamia, formed around big rivers, so the implications of these findings extend well beyond the Indus. Research in this area has been focusing on the role of rivers drying up leading to abandonment of urban centres by ancient communities. However, the researchers in today's study suggest their work could help archaeologists to take a fresh look at the development of urbanisation in early civilisations. Explore further: Scientists trace how rivers change course.",https://phys.org/news/2017-11-scientists-himalayan-rivers-ancient-indus.html?utm_campaign=awesummly&utm_source=awesummly
